,S.No.,tweetid,tweettext
0,1,karpathy,"A report on the geopolitics of AI by @timhwang, especially found Part 3 interesting  https://arxiv.org/abs/1803.08971¬†, and the highly related ""U.S. Semiconductor Manufacturing: Industry Trends, Global Competition, Federal Policy""  https://fas.org/sgp/crs/misc/R44544.pdf¬†‚Ä¶"
1,2,karpathy,"Growing as a programmer is to a large extent the accumulation of scars in your mind, which burn with each new line of code proportional to the expected pain inflicted on your future self over all possible refactoring."
2,3,karpathy,‚ÄúThe state of the art in explanation of a concept‚Äù - a phrase I first heard in a chat with @3blue1brown a while ago but has lingered with me since. Why shouldn‚Äôt there be an effort to seek/recognize such a thing for all concepts
3,4,karpathy,2023+: only those with access to powerful AGIs can now register for the NIPS conference.
4,5,karpathy,plan: 2019: be ready & fully caffeinated the millisecond it goes up 2020: write some JS to register me instantly 2021: discover the physical location of the NIPS backend & plug in via fibre optic next door 2022: orchestrate a DDOS attack of requests for my registration 2023: ???
5,6,karpathy,"My morning coffee turned out to be the difference between going and not going to NIPS 2018 this year. Apparently sold out in <15 minutes. I laughed at this diagram a year ago, but today it is too real. https://twitter.com/soumithchintala/status/909057642731130880¬†‚Ä¶"
6,7,karpathy,"Available video speeds on YouTube: 0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 2.0. What monster left out the 1.75x"
7,8,karpathy,‚ÄúA Magazine Is an iPad That Does Not Work‚Äù  https://youtu.be/aXV-yaFmQNk¬† a fave video. As our technosphere becomes more advanced & pervasive it is increasingly difficult to distinguish it from raw physics. Eg one day it will be odd that there was a time you couldn‚Äôt talk to all objects
8,9,karpathy,Full Body Surrogacy for Collaborative Communication  https://www.youtube.com/watch?v=Nrc7gH6dydw¬†‚Ä¶ interesting
9,10,karpathy,@prajjwal_1 should clarify that PhD for me was not a matter of deep thought and analysis so the quora post suggests. I felt it strongly and intuitively that I loved learning and wanted to be at the forefront of knowledge in some area. It was an emotional choice.
10,11,karpathy,"""Hybrid Optical-Electronic Convolutional Neural Networks""  http://www.computationalimaging.org/publications/hybrid-optical-electronic-convolutional-neural-networks/¬†‚Ä¶ incredibly interesting work - develops a hybrid optoelectronic CNN with an optical CONV1 layer that operates at zero power consumption (with rest of the forward pass in electronics (for now))"
11,12,karpathy,"@gwern That‚Äôs it!! It‚Äôs one of few short stories with a very good ratio of uniqueness, creativity and apparent ridiculousness to actual plausibility when you think about it a bit longer. Has become a favorite reference. Thanks!!"
12,13,karpathy,"There was an interestingly prophetic short story that has left a lasting impression on me and now can‚Äôt find. It‚Äôs few decades old and describes a highly accelerated future with people going through multiple jobs, partners, and rich and bankrupt cycles each day. Rings any bells?"
13,14,karpathy,Great post exploring the details of one of the first few programs. https://twobithistory.org/2018/08/18/ada-lovelace-note-g.html¬†‚Ä¶
14,15,karpathy,"@DanBrink91 Yeah, I wanted to impulse buy Stanford‚Äôs undergrad Physics book the other day and it was around $280. Like whoa."
15,16,karpathy,@ChrisTorresLugo Oh wow!!
16,17,karpathy,"was trying to compile the list based on courses at schools and which books they use to make this a bit more data driven, but gave up 2 hours into it. Very difficult information to find, absence of any schema."
17,18,karpathy,Discovering (paradoxically late in life) that I get more out of textbooks than books and that I don‚Äôt have to stop buying them just because I‚Äôm out of school. Good reading list pointers: https://www.lesswrong.com/posts/xg3hXCYQPJkwHyik2/the-best-textbooks-on-every-subject¬†‚Ä¶
18,19,karpathy,"@madebyollin sorry, not sure what happened there. I went, did a reboot and all seems well now. This thing is a ticking time bomb, I'll need to try to find some cycles on a weekend to investigate. sorry for the disruption!"
19,20,karpathy,"@OpenAI Was quite fun watching the OpenAI Five match earlier today, despite my limited awareness of DOTA macro strategy. Silicon beat meat 2-1, (1 with hero draw handicap). Congrats team at @openai on win & fun event! pic.twitter.com/HIYkSKp7gF"
20,21,karpathy,"""An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling""  https://arxiv.org/abs/1803.01271¬† good to see more papers on the topic - always start with a CNN before reaching for an RNN. You'll be surprised with how far you can get."
21,22,karpathy,"@TriTexan haha, yes.  https://en.wikipedia.org/wiki/Tesla_(microarchitecture)¬†‚Ä¶"
22,23,karpathy,"The latest entry in turning ImageNet into MNIST: 75.8% top-1 test accuracy with ResNet-50 (90 epochs) in 6.6 minutes using 2048 Tesla P40 GPUs  https://arxiv.org/abs/1807.11205¬† 64K ""mini""-batch size, mixed precision training, LARS, BN&bias weight decay at zero, custom all-reduce"
23,24,karpathy,@michael_nielsen @ch402 @dennybritz @seb_ruder @YannFletBerliac haven't used it yet but was impressed with a demo of  http://www.djlu.fr/¬†
24,25,karpathy,That deeply soul crushing feeling when you're super excited to try out this new thing you just impulse bought only to discover that batteries are not included. To add insult to injury sometimes manufacturers go the extra mile and require you to also remove screws to install them.
25,26,karpathy,Fantastic set of videos on building a programmable 8-bit computer from scratch on breadboards using only simple logic gates  https://eater.net/¬† & direct link to playlist https://www.youtube.com/watch?v=HyznrdDSSGM&list=PLowKtXNTBypGqImE405J2565dvjafglHU¬†‚Ä¶
26,27,karpathy,@SalehCU Precise tweets are less fun :D
27,28,karpathy,It took me a while to really admit to myself that just reading a book is not learning but entertainment.
28,29,karpathy,"@jigarkdoshi I know, I was making fun of this in my reddit comment here  https://old.reddit.com/r/MachineLearning/comments/86gurl/r_group_normalization_fair/¬†‚Ä¶ , but I didn't call this one :\ ü§¶‚Äç‚ôÇÔ∏è"
29,30,karpathy,The quest for optimal normalization in neural nets continues. SwitchNorm: add BatchNorm + InstanceNorm + GroupNorm with a learnable blend at each layer  https://arxiv.org/abs/1806.10779¬† fun plots; + code https://github.com/switchablenorms/Switchable-Normalization¬†‚Ä¶
30,31,karpathy,6) thinking view() and permute() are the same thing (& incorrectly using view)
31,32,karpathy,"@kasiahayden @mat_kelcey yep, happened to me a few times that I turn my data back on and get the same loss :) also if doing this produces a nice/decaying loss curve, this usually indicates not very clever initialization. I sometimes like to tweak the final layer biases to be close to base distribution."
32,33,karpathy,"@kasiahayden @mat_kelcey exactly. I like to start with the simplest possible sanity checks - e.g. also training on all zero data first to see what loss I get with the base output distribution, then gradually include more inputs and scale up the net, making sure I beat the previous thing each time."
33,34,karpathy,"@kasiahayden @mat_kelcey it's by far the most ""bang for the buck"" trick that noone uses that exists."
34,35,karpathy,"oh: 5) you didn't use bias=False for your Linear/Conv2d layer when using BatchNorm, or conversely forget to include it for the output layer .This one won't make you silently fail, but they are spurious parameters"
35,36,karpathy,most common neural net mistakes: 1) you didn't try to overfit a single batch first. 2) you forgot to toggle train/eval mode for the net. 3) you forgot to .zero_grad() (in pytorch) before .backward(). 4) you passed softmaxed outputs to a loss that expects raw logits. ; others? :)
36,37,karpathy,Scalable Deep Reinforcement Learning for Robotic Manipulation  https://ai.googleblog.com/2018/06/scalable-deep-reinforcement-learning.html¬†‚Ä¶ hand-designed init -> 580k grasp attempts on 7 robot arms over 4 months (raw monocular RGB camera input) -> 1.2M param net -> 96% successful test set grasps pic.twitter.com/zn2EyrKYZy
37,38,karpathy,e.g. RL DNN trained on CSGO would likely relatively quickly but somewhat unimpressively become a superhuman aimbot
38,39,karpathy,would be interesting to see a strategy game (e.g. Starcraft/DOTA) match mode with focus on strategy & taking out agility. E.g. slow down game 20x so battles can be easily micro'd on human time scales (?). related discussion in http://www.gamesbyangelina.org/2018/06/good-luck-have-fun/¬†‚Ä¶
39,40,karpathy,"@DavyLandman Ty aware of some existing projects in the space that don‚Äôt go far enough (today), unaware of papers."
40,41,karpathy,"Fun project request following up on last tweet: visually render in 3D code bases (git repos) to look like construction / factory. Modules become sites, topology follows function calls, compute becomes movement, developers swarm around in yellow hats building it..."
41,42,karpathy,"Spent some time at the factory last night. Felt like Alice in Wonderland, except with Wonderland as the home planet of the Transformers. I love software, but editing text files at a computer is nowhere near as viscerally overwhelming."
42,43,karpathy, pic.twitter.com/BkTRjWp0vs
43,44,karpathy,"Congratulations Reddit for being one of the most annoying websites begging you to download the app when there is zero need for it. Your perseverance, invasiveness, UI trickery and changing tactics have fooled me a number of times to accidentally click on the app link. üëè 10/10"
44,45,karpathy,"Was interesting to see this year‚Äôs industry expo and its scale, surrounding the poster session. The first time I visited CVPR it was a few tables in the back corner"
45,46,karpathy,"Was very fun to bring Tesla to #cvpr2018, in style. With the Model X at our booth I think we accidentally sold a few cars :) pic.twitter.com/0m6vOA79qK"
46,47,karpathy,"Through-Wall Human Pose Estimation Using Radio Signals  http://rfpose.csail.mit.edu/¬†  ""wireless signals in the WiFi frequencies traverse walls and reflect off the human body. It uses a deep neural network approach that parses such radio signals to estimate 2D poses."""
47,48,karpathy,"#randomscifisundays Exhalation, from Ted Chiang  http://www.lightspeedmagazine.com/fiction/exhalation/¬†‚Ä¶ steampunk spin on heat death of the Universe"
48,49,karpathy,Jeff Bezos @ ISDC 2018 https://www.geekwire.com/2018/jeff-bezos-isdc-space-vision/¬†‚Ä¶
49,50,karpathy,@JannickePS @CERN @arxiv_org @KyleCranmer @lukasheinrich_ very cool! hope it wasn't too hard to get working. Feel free to submit PRs to the Readme if you happened to come across some undocumented / unobvious parts.
50,51,karpathy,"lots of exciting recent work in large-scale distributed training of neural nets: (very) large-batch SGD, KFAC, ES, population-based training / ENAS, (online) distillation, ... üî•"
51,52,karpathy,"@lishali88 I‚Äôve used Software 2.0 to refer to the resulting artifact, the final piece of code, only portion of which is human designed. The act of writing it is a kind of fill in the blanks programming where you only write the general scaffolding."
52,53,karpathy,"@pwang Oooh, nice. üëè:)"
53,54,karpathy,"@andrey_kurenkov not a fan because ""learning"" is too overloaded and brings a lot of baggage, and also ML as a field / set of techniques is broader than the trend described"
54,55,karpathy,"not a huge fan of the term ""differentiable programming"". The big deal isn't that it's differentiable, it's that there is any optimization over the code at all, instead of explicit code. I like/started to use ""fill-in-the-blanks programming"", artifacts of which are Software 2.0 :)"
55,56,karpathy,@s_m_i Closes at 5pm ;( This is the problem with libraries. Otherwise it looks beautiful!
56,57,karpathy,"@s_m_i I spent a lot of time there! Something just like it but with coffee/food closer, and at the edge of a cliff overlooking the ocean or some crazy garden :)"
57,58,karpathy,@michael_nielsen Interesting! An uncharted search space :)
58,59,karpathy,"Searching for a place in some vicinity of Bay Area, pretty, quiet, with WiFi, ability to sit down for few hours and read/work. I know it exists somewhere out there."
59,60,karpathy,"Good recent episode on Rationally Speaking podcast on one of my favorite subreddits, r/changemyview ( https://www.reddit.com/r/changemyview/¬†).  Mentions a 2016 paper on the sub:  https://chenhaot.com/papers/changemyview.html¬†‚Ä¶"
60,61,karpathy,"@neurograce @neuroecology @AnneEUrai my original post has a bit more info:  https://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/¬†‚Ä¶ would be interesting to AMT it, but suspect would need a similar custom UI, and a lot of training. I suspect ensembles of well-trained humans could do better than 5%"
61,62,karpathy,"@neuroecology @neurograce @AnneEUrai Great question. Original data is from google image search (basically) by googling the text, and then cleaning up the results with a binary correct / not correct from humans."
62,63,karpathy,"@neurograce @AnneEUrai @neuroecology It is me, because I couldn‚Äôt find anyone else who wanted to train for 3 weeks, and when they did much worse."
63,64,karpathy,"@neurograce @AnneEUrai @neuroecology If by one day you mean 3 weeks, and a number of attempts to include other people trained to various levels of expertise."
64,65,karpathy,"Towards battery-free HD video streaming  http://batteryfreevideo.cs.washington.edu/¬† ""we can harvest sufficient energy to enable battery-free 30 fps 1080p video streaming at up to 8 feet."" Backscatter is on a roll, for better or worse, and mix of both."
65,66,karpathy,"Duplexes talking to duplexes would be an amusing use of existing (human) interfaces but by AIs. Just like autonomous cars use existing roads/signs for humans, or how our ""world of bits"" AI at OpenAI used simulated keyboard/mouse events to interact with web pages. Very amusing."
66,67,karpathy,"Great to see roadmap for production support in PyTorch and, very importantly, on strictly opt-in basis üëç. The feature/attribute tradeoffs you'd like from a good DL framework vary between workflows quite a lot (~ debugging/dev, training @ scale, inference @ scale) https://twitter.com/PyTorch/status/991727733846650880¬†‚Ä¶"
67,68,karpathy,@gabzolina very nice. what are we looking at exactly?
68,69,karpathy,"PyTorch 0.4.0 is out!  https://github.com/pytorch/pytorch/releases/tag/v0.4.0¬†‚Ä¶ lots of welcome additions: Variables/Tensor merge, more numpy-likeness (dtypes, *_like, pro indexing...), much easier to write CPU/GPU agnostic code, gradient checkpointing for memory-efficient backprop, reduce=False, distributions üëè"
69,70,karpathy,Delighted to stumble by this article bringing more attention to Stanislaw Lem and his work. Very high ratio of intellectual depth vs obscurity. http://m.nautil.us/issue/28/2050/the-book-no-one-read¬†‚Ä¶
70,71,karpathy,"@Ronald_vanLoon @randal_olson @hmason +1 me as well, thank you."
71,72,karpathy,@de3ug After 7pm?
72,73,karpathy,@sdavidmiller numpy!
73,74,karpathy,"1 hour and 5 diagrams later I optimized 100 lines of code that ran in 13 seconds to 20 lines of heavily vectorized code that runs in 0.02 seconds, and this might just be the best day of my life, so far."
74,75,karpathy,"@mikb0b even then, I'd be inclined to use a compute heater on moral grounds alone. At least it's doing _something_ ""useful"" with the heating. Heating just for heating makes me sad."
75,76,karpathy,"The QC-1 ""Crypto heater"" doesn't waste entropy, heats your house while mining ETH, pays for itself in ~5 years https://www.theverge.com/circuitbreaker/2018/3/9/17100068/qarnot-qc-1-cryptocurrency-mining-rig-heater-home-electricity-ethereum¬†‚Ä¶"
76,77,karpathy,"Another fun entry joins the growing ""RL Anonymous"" collection, documenting 8 months of trying to get RL to work  http://amid.fish/reproducing-deep-rl¬†‚Ä¶ reminded of my contribution to the collection from ~year ago in HN comments:  https://news.ycombinator.com/item?id=13519044¬†‚Ä¶"
77,78,karpathy,"@shuieryin Try overfitting on a single fixed batch with a very small learning rate. If that doesn‚Äôt work it‚Äôs probably a bug. It‚Äôs not common to backward individual layers/losses manually like in your example, usually you set up the full model and backdrop whole thing. Also use pytorch :)"
78,79,karpathy,"Got a chance to try out a Bird ( https://www.inc.com/will-yakowicz/the-bird-electric-scooter-phenomenon.html¬†‚Ä¶) this morning and it is THE BEST. Waiting for someone to photoshop it as the next stage into one of those ""evolution of man"" pictures."
79,80,karpathy,"@backus haha, it looks like we had the same fun saturday project"
80,81,karpathy,"@TheAtlantic @jimmfleming @michael_nielsen 3) paper that is persistent and can simultaneously be edited by multiple people, and forked/versions like Github code? :)"
81,82,karpathy,"@TheAtlantic @jimmfleming @michael_nielsen a better paper and pen might be 1) paper that supports delete/cut/copy/paste (e.g. iPad like), and 2) paper augmented with a layer intelligence, e.g. auto-suggesting things to bring into the picture, completing diagrams / calculations, etc? :)"
82,83,karpathy,"@TheAtlantic @michael_nielsen It's frustrating how thinking feels like exploring a large idea cave serially with a tiny flashlight. It's a bit shocking how underdeveloped our tooling is in surpassing limitations of thinking / short term memory. Pen & paper was a good first step, haven't taken too many since."
83,84,karpathy,"""As We May Think"" Vannevar Bush in 1945 trying to predict future  https://www.theatlantic.com/amp/article/303881/¬†‚Ä¶ ""A memex is a device in which an individual stores all his books, records, and communications, [...] it may be consulted with exceeding speed and flexibility. [...] supplement to his memory."""
84,85,karpathy,"Haha, ""YOLOv3: An Incremental Improvement""  https://pjreddie.com/media/files/papers/YOLOv3.pdf¬†‚Ä¶ reads like good stand up comedy"
85,86,karpathy,"@jesseallhands yes, i meant VI - typo"
86,87,karpathy,"@tarinziyaee Oh crap, it‚Äôs 5am already? Let‚Äôs check my calendar for tomorrow"
87,88,karpathy,"Worse, I watched a few YouTube videos on it on my phone (no incognito) and now the YouTube recommendation model must be getting all excited and ready to tempt me with more videos for months."
88,89,karpathy,I‚Äôve resisted Civilization IV: Rise and Fall expansion for almost a month and a half now. This morning after an article I thought I‚Äôll check it out for just one game. But I know where that path leads. I must stay strong.
89,90,karpathy,@randal_olson Empirically looks they way so far for the most challenging problems. Not religiously tied to it otherwise
90,91,karpathy,"""Alexa, turn on the light!"". ""A few devices share that name, which one do you want?"". ""Living room"". ""A few devices share that name, which one do you want?"" ""Ohhh, shut up"". ""This device is not responding"". Just a regular day in a life of Alexa."
91,92,karpathy,It's very rewarding to watch the early feedback on our latest Autopilot update:  https://electrek.co/2018/03/16/tesla-autopilot-update-first-drive-videos/¬†‚Ä¶ a result of a fairly extensive rewrite. Working hard to get more of it polished and out there!
92,93,karpathy,"If you squint a bit academia is a kind of blockchain. Each paper is a transaction, a block is a conference. The reviewers determine if a block is valid (except with effectively zero ""mining"" reward :\). Paper citations are pointers to the previous block(s). Maybe? no? okay"
93,94,karpathy,"Idea for a ""metalearning-chess"" variation: keep the dynamics the same but make the reward function for each game be some (fixed) random function of the game board (e.g. a random linear or a depth 2 regression tree) that the players observe a sample from at end of their turn."
94,95,karpathy,"I often try to remind myself that it‚Äôs only ~6 years ago that I was hacking custom architectures with manually written backwards pass in Matlab, running on a single machine on the CPU."
95,96,karpathy,It is starting to look like deep learning workflows of the future feature autotuned architectures running with autotuned compute schedules across arbitrary backends. I don't know if I should be excited or scared.
96,97,karpathy,"@sjmielke I know, I know, once you see it, you cannot unsee it :)"
97,98,karpathy,"@vitaliy @iandanforth OneNote might in fact be closest to what I had in mind so far, will do; (cc @Vitaliy)"
98,99,karpathy,"@Simply_Sukumar definitely not. don't think slides with cool transitions. think 100page documents packed with information that need laying out, tagging, linking, sorting, searching, ..."
99,100,karpathy,"I lack a tool to ""lay out"" image/text information visually. Like a word doc but not just linearly downwards, but all around on a large 2D plane, with ability to zoom in/out, etc. Really doubt that we've reached anywhere close to the peak of UI tooling for the brain."
100,101,karpathy,"@fchollet it's based on arxiv-sanity data, so: cs.[CV|CL|LG|AI|NE]/stat.ML"
101,102,karpathy,"(sorry, percentages in original tweet only refer to the last month. looking at the totals so far it's 5.9% of all papers in database mentioned TensorFlow, 5.4% Caffe, 3.2% Theano, 2.3% Keras, 1.6% Torch, 1% PyTorch, 0.5%- for others)"
102,103,karpathy,"(this is using the same code that I used in generating the original figure in my earlier Medium post  https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106¬†‚Ä¶ from Apr7, 2017)"
103,104,karpathy,"Unique mentions of deep learning frameworks in arxiv papers (full text) over time, based on 43K ML papers over last 6 years. So far TF mentioned in 14.3% of all papers, PyTorch 4.7%, Keras 4.0%, Caffe 3.8%, Theano 2.3%, Torch 1.5%, mxnet/chainer/cntk <1%. (cc @fchollet) pic.twitter.com/YOYAvc33iN"
104,105,karpathy,"Google Search trends: Deep Learning vs. Bitcoin. Search traffic is not the best proxy, but I find it interesting that so many of my friends in AI, when asked to guess, guess this relationship consistently waaay off. pic.twitter.com/ZoRiaRedHm"
105,106,karpathy,"miniaturization, decreasing hardware costs and intelligence at the edge. starts to look a bit like the beginning of a synthetic Cambrian explosion https://twitter.com/Harvard/status/967759846257733635¬†‚Ä¶"
106,107,karpathy,"@jigarkdoshi fixed, thanks."
107,108,karpathy,"""It is believed by many that electricity fulfills more of the necessary conditions of a successful motive power for motor carriages than any other power. It is clean, compact, noiseless, free from vibration, heat, dirt and gases, and is under perfect control."" -1900 wisdom :)"
108,109,karpathy,"this find has made my day: ""The Progress of Invention in the Nineteenth Century"", written in 1900.  https://www.gutenberg.org/files/41538/41538-h/41538-h.html¬†‚Ä¶"
109,110,karpathy,My email app icon badge shows that I have 1 unread email but when I open it I can‚Äôt see/find it. Hashtag the struggles of modern age :‚Äô(
110,111,karpathy,@goodfellow_ian @pfau @quasimondo üëè
111,112,karpathy,"also reminds me of SENets. Information mixes too slowly across space in vanilla CNNs. would normally compensate for with increasing depth, dilated convs etc., this looks like another way."
112,113,karpathy,"seeing self-attention (a kind of global ""message passing"" operation) popping up in a number of places recently, following ""attention is all you need"" paper ( https://arxiv.org/abs/1706.03762¬†) for MT. e.g., recently  https://arxiv.org/abs/1711.07971¬†,  https://openreview.net/forum?id=r16Vyf-0-¬†‚Ä¶ etc."
113,114,karpathy,SysML (a new systems + machine learning conference) happening today @ Stanford + live stream available http://www.sysml.cc/¬†
114,115,karpathy,"""Deep Reinforcement Learning Doesn't Work Yet""  https://www.alexirpan.com/2018/02/14/rl-hard.html¬†‚Ä¶ great read, hits a lot of points I've also come to realize over last ~2 years. 70% is a vast understatement."
115,116,karpathy,"Quite like the pedagogy of this visual, concrete, example-driven, ""live demo"" approach to a blockchain tutorial  https://anders.com/blockchain¬†"
116,117,karpathy,"neat, ICLR 2018 papers sorted by their score  https://chillee.github.io/OpenReviewExplorer/index.html¬†‚Ä¶ would be fun to see it sorted by score ""entropy"" too, those papers can be quite good."
117,118,karpathy,New Boston Dynamics video is making rounds  https://www.youtube.com/watch?v=fUyU3lKzoio¬†‚Ä¶ looks very cool! Just a bit worried that behind the scenes is a team of people over the last few months carefully crafting a full state machine for this demo.
118,119,karpathy,"It looks like if you bombard Earth with photons for a while, it can emit a Roadster. hah"
119,120,karpathy,There is a Roadster in space. And it has a live feed:  https://www.youtube.com/watch?v=aBr2kKAHN6M¬†‚Ä¶ definitely the fastest car :) pic.twitter.com/2XR05bg1ON
120,121,karpathy,"@michael_nielsen @MichaelNied1 I randomly noticed it in a bookstore, didn't do much research about it before. It's called ""The Unnatural World"". Only ~quarter way through it so can't recommend yet."
121,122,karpathy,"@elontimes yes, like that, but with more deep learning LSTM something something :)"
122,123,karpathy,"@michael_nielsen @Eklavya_FCB hmm, but I find Anki's very non-flashy, clunky, looks-like-someones-side-project UI kind of endearing :D"
123,124,karpathy,Makes me want to work on a browser extension where you can highlight some text from an article on the web and the extension suggests Anki cards to add to your collection.
124,125,karpathy,"I tried to Ankify some facts yesterday from a book I'm reading (on how humans are destroying nature, it's really quite uplifting), but find the [book-reading] <-> [Ankifying on laptop] handoff to be somewhat awkward. @michael_nielsen - tips?"
125,126,karpathy,"Getting fairly addicted to Anki as a result of this twitter thread from @michael_nielsen & few posts I've encountered in the past  https://www.gwern.net/Spaced-repetition¬†‚Ä¶. Was easier than I expected to learn lots of countries/states/flags. Wish there were more ""open-sourced"" anki decks out there. https://twitter.com/michael_nielsen/status/957763229454774272¬†‚Ä¶"
126,127,karpathy,The Secret Life of Plankton  https://youtu.be/xFQ_fO2D7f0¬† i still can't quite wrap my head around our laws of physics apparently just resulting in the whole party
127,128,karpathy,"- Sometimes find my phone in morning uncharged. I suspect alerts vibrate the phone to the edge of the charging plate? - The ""sound++"" button is directly opposite to ""off"" button & pressing both takes screenshot => lots of accident screenshots when just trying to turn off screen."
128,129,karpathy,"@layon_overwhale you had to press the button to wake the phone, and then swipe. now you just swipe. so if you simply roll the phone around your hand, you can now swipe to the camera and start recording videos quite easily by accident."
129,130,karpathy,My iPhoneX switch has turned out to be a UX regression: - Face ID doesn't work: when phone is on table next to me. when I try to check it from bed in am hours. halfway through a yawn. leaning on my hand. - Often accidentally swipe to camera when I play with the phone in my hand
130,131,karpathy,"@PowerDNS_Bert @visarga absolutely! gene regulatory networks look very much like neural networks, except implemented in chemistry at slower time scales"
131,132,karpathy,@rupspace The code would be readable just fine basically forever. We can fight about this later :)
132,133,karpathy,DNA seen through the eyes of a coder  https://ds9a.nl/amazing-dna/¬† I like this a lot.
133,134,karpathy,"@Grady_Booch Haha, i'm talking about (convolutional neural network) architectures. As I always do."
134,135,karpathy,"@filippie509 hahah :D. ""We propose a new architecture (see Appendix A). Section 2: Experiments"""
135,136,karpathy,"Instead trying to describe an architecture in a paper with words, tables and diagrams across 2 sections and 4 pages, it is 90% of the time possible to just paste the 100 lines of code into Appendix A."
136,137,karpathy,UC Berkeley EECS Colloquium talk on GraphCore's Colossus IPU https://www.youtube.com/watch?v=7XtBZ4Hsi_M¬†‚Ä¶
137,138,karpathy,"faster-rcnn.pytorch  https://github.com/jwyang/faster-rcnn.pytorch¬†‚Ä¶ object detection is deceivingly highly error-prone, tricky, and labor intensive to get right. Great to see nice, open source, and evaluated implementations."
138,139,karpathy,@cipri_tom None ^_^
139,140,karpathy,@EmilWallner when i first read it: cool! now: ugh.
140,141,karpathy,"A long while ago I came across a great document describing the human brain strictly as a computing device, from a computer scientist / systems perspective. Can't find anymore ;( (trying to Google it is only surfacing Neuralink news articles...)"
141,142,karpathy,Reading Silicon: How to Reverse Engineer Integrated Circuits  https://www.youtube.com/watch?v=aHx-XUA6f9g¬†‚Ä¶ wow. I felt proud reverse engineering x86 binaries and was unaware of this next level.
142,143,karpathy,"Curiously, the dynamics of this system are such that when you bombard hot earth stuff with photons for a while, it eventually transforms into intricate molecular fractal patterns of vegetation, humans/animals, cities, cars, chips etc. must look funny ‚Äúzoomed out‚Äù & played forward"
143,144,karpathy,"@tpanum felt a bit too much like a washed-down, slightly more mysterious outtake from Terminator"
144,145,karpathy,"@layon_overwhale I liked that it's one of the more believable and very much on the horizon episodes. You already see the same things happening today in more limited ways, placing well-intentioned people (with our psychology bugs) in technologically-enabled knots / conundrums."
145,146,karpathy,"@whiskeyandwry Agree, they are starting to recycle some themes now, not always with a fresh enough perspective."
146,147,karpathy,@agbutteriss what _really_ bothered me is that person's memories are obviously not encoded in their entirety in their DNA. It's just dumb.
147,148,karpathy,@TJzafar haha barely!
148,149,karpathy,Overall a solid season. I like that there seems to be a lot of disagreement over the episode ranking with people i've talked to / articles i've seen
149,150,karpathy,"Black Mirror Season 4: 1. ""Hang the DJ"" - fun twist 2. ""USS Callister"" - entertaining but unrealistic 3. ""Arkangel"" - good ""well-intentioned tech gone wrong"" story 4. ""Black Museum"" - trying a bit too hard 5. ""Crocodile"" - well that escalated quickly 6. ""Metalhead"" - yeeeeahno"
150,151,karpathy,Cool analysis (but overall a bit of a missed opportunity) from RescueTime on productivity trends  http://blog.rescuetime.com/225-million-hours-productivity/¬†‚Ä¶ I like the peak productive for software eng chart. (During PhD I did most of my most productive work at 3am. Now forced to adopt normal working hours :( )
151,152,karpathy,@RuchiJain_ 5 out of 5 means there are only very few reviews
152,153,karpathy,Basically everything is rated in range of 3.5-4.2 out of 5.
153,154,karpathy,China Shuts Down Its Legal Ivory Trade  https://news.nationalgeographic.com/2017/12/wildlife-watch-china-ivory-ban-goes-into-effect/¬†‚Ä¶ prices of ivory drop 65%. %chance of a good future += 0.0001
154,155,karpathy,"@_karfly a great specimen, adding! :)"
155,156,karpathy,"Visual Domain Decathlon - classify 10 datasets at the same time  http://www.robots.ox.ac.uk/~vgg/decathlon/¬† a fun setup, brings some problems that are rare in academia but common in industry to the forefront, e.g. large data imbalances, multi-task learning, forgetting, domain adaptation"
156,157,karpathy,Block-Sparse GPU Kernels release from OpenAI https://blog.openai.com/block-sparse-gpu-kernels/¬†‚Ä¶
157,158,karpathy,"Some strong results reported in Chess from AlphaZero (an AlphaGo generalization)  https://arxiv.org/abs/1712.01815¬† winning against a 64 thread 1GB hash Stockfish 28-72-0. Not obvious if it's a comparable ""compute footing"", but the games are fun to step through:  https://lichess.org/study/EOddRjJ8¬†"
158,159,karpathy,"(Thanks to everyone who expressed interest. Tonight's event is being postponed, we'll share more information soon)"
159,160,karpathy,To friends attending NIPS: we'd like to invite you to our AI fireside chat and party!  Starts at 7pm tonight. If you‚Äôd like to join email conversation@tesla.com with your name/affiliation and we‚Äôll do our best to get as many people in as possible! pic.twitter.com/Cth9lrJpss
160,161,karpathy,(bracing myself for people who really like Photoshop and feel strongly that this is really just a continuation of the smart brush :))
161,162,karpathy,"@SethHWeidman Nice, but don't think you're seeing the full force and scope of my original post. (Which of course is my fault for not explaining it too well.) This isn't about classifiers specifically, e.g. RL agents (AlphaGo etc) aren't classifiers. Scikit Learn doesn't scratch the surface."
162,163,karpathy,"HoME: a Household Multimodal Environment  https://home-platform.github.io/¬† looks pretty cool! vision, audio, semantics, physics, and interaction with objects and other agents & open-source, OpenAI Gym-compatible."
163,164,karpathy,"Wow, GANs are on a roll. Quite amazing results from pix2pixHD:  https://tcwang0509.github.io/pix2pixHD/¬† Also the most tangible glimpse so far into what I keep referring to as a future Photoshop 2.0"
164,165,karpathy,"Can't find a website, but name is Sean Kilcoyne (sean3v@hotmail.com). A lot of beautiful work. (@ Market in SF near ferry building)"
165,166,karpathy,Randomly picked up this beauty from an artist on a street market. pic.twitter.com/4fKTcIoOgB
166,167,karpathy,"@Imaculate3 nope, long gone, forever."
167,168,karpathy,@_AntreasAntonio \alpha_k ? :) Almost my initials
168,169,karpathy,Haha! :) And I thought I'd have to stay in physics if I wanted my own constants. https://twitter.com/fhuszar/status/933683427894841345¬†‚Ä¶
169,170,karpathy,"@thvasilo it's in the plans, for the last year :) I wish I had the time, sorry :("
170,171,karpathy,"Very good reading from Rodney Brooks ""The seven deadly sins of predicting the future of AI""  https://rodneybrooks.com/the-seven-deadly-sins-of-predicting-the-future-of-ai¬†‚Ä¶"
171,172,karpathy,"New blog post: ""Software 2.0"" https://medium.com/@karpathy/software-2-0-a64152b37c35¬†‚Ä¶"
172,173,karpathy,@taehoonleeml looks like @RemiCadene also has a PyTorch implementation here as few hours ago:  https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/nasnet.py¬†‚Ä¶
173,174,karpathy,"@taehoonleeml wow, nicely done! (if equivalent.) need to step through :s, really not looking forward to"
174,175,karpathy,"Google released NASNet in TF a ~week ago, which is exciting  https://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet¬†‚Ä¶ the code is a bit difficult to parse but it's nice to have the models. Impressive speed-accuracy tradeoffs."
175,176,karpathy,"TensorFlow Eager  https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html¬†‚Ä¶ now more like Chainer, as a response to PyTorch"
176,177,karpathy,"@hardmaru @gwern (e.g. forward a batch through backbone, then pick pairs, make virtual examples batch, evaluate loss, and backprop the whole thing) maybe"
177,178,karpathy,"@hardmaru @gwern also ""where (xi,yi) and (xj,yj ) are two feature-target vectors drawn at random from the training data"". could backprop through the interp?"
178,179,karpathy,"@hardmaru @gwern I had the same question. Paper does say ""prior knowledge that linear interpolations of feature vectors should lead to linear interpolations"""
179,180,karpathy,Efficient Processing of Deep Neural Networks: A Tutorial and Survey  https://arxiv.org/abs/1703.09039¬† good reading.
180,181,karpathy,"@mrdonut oh yeah :s sorry, i'll try to bring it back. will call them to see what's happening."
181,182,karpathy,"(the phrase ""pretty cool"" is specific, and refers to my earlier post on VR problems  https://medium.com/@karpathy/virtual-reality-still-not-quite-there-again-5f51f2b43867¬†‚Ä¶)"
182,183,karpathy,"""Why Snapchat Spectacles failed""  https://news.ycombinator.com/item?id=15576751¬†‚Ä¶ I had both Google Glass & Spectacles. They were ""pretty cool"", like VR, Kinect etc."
183,184,karpathy,@jacobandreas üî•üî•üî•
184,185,karpathy,Article also correct to point out the very small few months (~3) payback costs wrt AWS for these kinds of configs
185,186,karpathy,"""DeepLearning11: 10x NVIDIA GTX 1080 Ti Single Root Deep Learning Server."" That's a lot of firepower for $16K https://www.servethehome.com/deeplearning11-10x-nvidia-gtx-1080-ti-single-root-deep-learning-server-part-1/#comments¬†‚Ä¶"
186,187,karpathy,"There are only a few things that compete for top spots on my ""what would I do with an exaflop computer"". This is now up there."
187,188,karpathy,0_o pic.twitter.com/M3yB6rzTiO
188,189,karpathy,"wow, blown away & hypnotized by results from Progressive Growing of GANs  https://www.youtube.com/watch?time_continue=1&v=XOxxPcy5Gr4¬†‚Ä¶ & code on github: https://github.com/tkarras/progressive_growing_of_gans¬†‚Ä¶"
189,190,karpathy,"@smc90 :) np, like the podcast! one of my favorites"
190,191,karpathy,"Heard my name name dropped on the latest a16z podcast during my morning commute, wrt AI. Unfortunately they think I work at Google ;'("
191,192,karpathy,"Good & quick to the point reading: ""Introduction to High Performance Scientific Computing"" [book pdf]  http://pages.tacc.utexas.edu/~eijkhout/Articles/EijkhoutIntroToHPC.pdf¬†‚Ä¶"
192,193,karpathy,"My fave part is that the prediction accuracy on professional moves goes up during training, and then eventually goes down a bit. Nice."
193,194,karpathy,"Should add that it's quite general, but within limits. Not all applications (most) allow a simulator and self-play https://medium.com/@karpathy/alphago-in-context-c47718cb95a5¬†‚Ä¶"
194,195,karpathy,"AlphaGo Zero  https://deepmind.com/blog/alphago-zero-learning-scratch/¬†‚Ä¶ v cool based on skim: no sup pretraining, raw board input, resnet, new training scheme. more magic."
195,196,karpathy,Stanford's EE380 Colloquium on Computer Systems videos https://www.youtube.com/playlist?list=PLoROMvodv4rMWw6rRoeSpkiseTHzWj6vu&disable_polymer=true¬†‚Ä¶
196,197,karpathy,@LH Sounds legit.
197,198,karpathy,The heat expelled from the back of a computer makes me sad.
198,199,karpathy,"@brandondamos e.g. sometimes the activations have strong columns, or are weirdly sparse or weirdly dense, or some ReLU neurons die, etcetc"
199,200,karpathy,"@brandondamos more generally, curious how one could measure overall ""health"" of a network. When you look at loss/activations/weights visually you can tell"
200,201,karpathy,"An uncharacteristically good discussion spotted on r/ML  https://www.reddit.com/r/MachineLearning/comments/75phd2/r_mixed_precision_training/?st=j8ntr6wo&sh=e59130db¬†‚Ä¶ TLDR: use trunc float32 (""bfloat16"") instead of float16"
201,202,karpathy,@pedrordz wat
202,203,karpathy,Every noise at once  http://everynoise.com/engenremap.html¬† lays out all possible music in 2D + spotify samples. very cool.
203,204,karpathy,@lishali88 @3blue1brown @dauber :) spotted on top of r/MachineLearning
204,205,karpathy,"I'm apparently quite late to the party, but I discovered a very good/thorough math YouTube channel; 3Blue1Brown: https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/featured¬†‚Ä¶"
205,206,karpathy,"@KelloggsUS Hi, there are not enough raisins in your Raisin Bran. This is causing me significant distress."
206,207,karpathy,"@jeremyphoward frequent conversation could be a hint of something amiss. I don't see insight from ""I used 50 pretrained CNNs on 100 scales and XGBoosted""."
207,208,karpathy,Kaggle competitions need some kind of complexity/compute penalty. I imagine I must be at least the millionth person who has said this.
208,209,karpathy,"My favorite quote is from the winning solution ( https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36809¬†‚Ä¶)  ""9.I tried bayesian inference but I found it was not helpful."" LOL"
209,210,karpathy,Reading through winners of the Amazon Space Kaggle competition  https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion¬†‚Ä¶ the solutions are out of control with ensembles
210,211,karpathy,(for a long while I preferred writing backprop manually in raw numpy instead of adopting Theano. irrationally so. good old days.)
211,212,karpathy,"RIP Theano  https://groups.google.com/forum/#!topic/theano-users/7Poq8BZutbY¬†‚Ä¶ I was never able to pick it up, but it was _the_ thing to use for deep learning for a good while."
212,213,karpathy,"""Facebook, you needy sonofabitch""  http://bradfrost.com/blog/post/facebook-you-needy-sonofabitch/¬†‚Ä¶ hits a nerve. You can measure my click throughs but you can't measure my annoyance"
213,214,karpathy,"When my loss goes down it's not ""cool, it's working!"", it is ""hmm it should be going down faster, something must be wrong"". Okay, </rant>."
214,215,karpathy,"The ""move fast & fix stuff until it compiles then it's probably fine"" approach is inadequate when each bug silently subtracts 2% accuracy."
215,216,karpathy,"To get neural nets to work one must be super-OCD about details. With bugs nets will train (they ""want"" to work), but work silently worse."
216,217,karpathy,"@hardmaru should be explicitly pointed that this is for an AlexNet, not ResNet-50 for which they match the time. Bit sketchy to put 24min in title."
217,218,karpathy,spotted on PyTorch Slack :D dynamicgraphs.png pic.twitter.com/Wgi4vL9yEQ
218,219,karpathy,"@hholst80 ""It might not catch an existing bug..."". that's a bug."
219,220,karpathy,One of more unintuitive Python gotchas is that assert is a statement not a function. Can easily introduce large bugs https://stackoverflow.com/questions/3112171/python-assert-with-and-without-parenthesis¬†‚Ä¶
220,221,karpathy,(I actually use a different 3-letter acronym but I'll try to keep my feed pg13 :))
221,222,karpathy,alias wat='python -m pdb -c continue' # you're welcome
222,223,karpathy,"""The Relationship Between Hurricanes and Climate Change""  https://www.nytimes.com/2017/08/25/us/hurricane-harvey-climate-change-texas.html¬†‚Ä¶ & Global Greenhouse Emissions data https://www.epa.gov/ghgemissions/global-greenhouse-gas-emissions-data¬†‚Ä¶"
223,224,karpathy,"(already linked to this once before) ""Risks with Infinite impact"":  https://api.globalchallenges.org/static/wp-content/uploads/12-Risks-with-infinite-impact.pdf¬†‚Ä¶ [pdf]"
224,225,karpathy,A ConvNet that is given a label before it did the forward pass cannot do the backward pass.
225,226,karpathy,Ideally never absorb information without predicting it first. Then you can update both 1) your knowledge but also 2) your generative model.
226,227,karpathy,"@usmanghani I found ""Professional CUDA C Programming"" lying around, read some, coded some, then just kept going. Didn't over-optimize on the choice here"
227,228,karpathy,I've only picked up GPU/CUDA at random. Actually working through CUDA book from Chapter1 proving to be something I should have done long ago
228,229,karpathy,@yashk2810 interns welcome!
229,230,karpathy,We're hiring strong ML/CV/Roboticists for the Tesla Autopilot Vision team. We ship autonomy at scale. Join us: vision@tesla.com
230,231,karpathy,@kevin_zakka More like no time to shave :p
231,232,karpathy,Last minute preparation for the Deep RL Bootcamp :) @pabbeel pic.twitter.com/9gGIu12lvk
232,233,karpathy,@necro351 see next tweet
233,234,karpathy,"If you voted ""other"" in the previous poll, the other is:"
234,235,karpathy,@moyix LOL
235,236,karpathy,Your editor.
236,237,karpathy,@yieldthought oh stop it! :)
237,238,karpathy,"not for any reason to do with humans. As in, the Universe is worse off without a forest than with a forest in some metric."
238,239,karpathy,It seems intuitive that a thriving life ecosystem (e.g. jungle) is valuable & that deforestation is morally wrong. Can't formalize why.
239,240,karpathy,Tonight is a good night to read through NVIDIA's V100 GPU architecture white paper  https://images.nvidia.com/content/volta-architecture/pdf/Volta-Architecture-Whitepaper-v1.0.pdf¬†‚Ä¶
240,241,karpathy,@anmolsj Not that I'm aware of
241,242,karpathy,":) would add few categories, esp profiling, size/interpretability of lib code base, distributed training, community/support, ..."
242,243,karpathy,Pretty good list. Except the article makes it sound like there's a contest. https://twitter.com/awnihannun/status/898341423862251522¬†‚Ä¶
243,244,karpathy,Straight forward progression. We first didn't learn anything. Then just the classifier. Then just the ConvNet params. Now also architecture.
244,245,karpathy,"Thanks for the link! TIL: ""Shepard Tone"", the musical illusion that monotonically builds tension https://twitter.com/voxdotcom/status/891104747347886080¬†‚Ä¶"
245,246,karpathy,"@prajax_ Wow, this is just about the best thing I've seen this month :D"
246,247,karpathy,@atroyn haha! I'll try it out today. I'm somewhat scared it will lose its punch if I keep it on repeat too long. Very few things punch quite like it
247,248,karpathy,"Listening to Hans Zimmer (e.g., ""no time for caution"" from the Interstellar docking scene) makes even the most mundane things feel Epic."
248,249,karpathy,"Awesome work from @OpenAI: Dota 2 bot, a neural net trained with self-play beats the world's top players at 1v1. Learns fun strategies! https://twitter.com/OpenAI/status/896157788908290048¬†‚Ä¶"
249,250,karpathy,"Neat, the CS231n 2017 lecture videos are now up:  https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv¬†‚Ä¶ I hear that was a lot of work :) great job @jcjohnss and @syeung10!"
250,251,karpathy,@geoffreyirving yeeea about that
251,252,karpathy,The updated ImageNet training example with support for distributed training is a beauty  https://github.com/pytorch/examples/blob/master/imagenet/main.py¬†‚Ä¶ clean 300 lines
252,253,karpathy,"PyTorch v0.2 release sooo goood  https://github.com/pytorch/pytorch/releases/tag/v0.2.0¬†‚Ä¶ more numpy-like (broadcasting/indexing), distributed training, also like retain_grad"
253,254,karpathy,Gradient descent can write code better than you. I'm sorry.
254,255,karpathy,"I'm not eligible to renew my driver's license online, or over mail with <60 days left & 1st in person appointment is in 4 months. Thanks DMV"
255,256,karpathy,"Spotted on the internet: ""reinforcement learning: the study of teaching computers how to beat Atari"". haha"
256,257,karpathy,"@akm Haha good point, we had a temporary regression there"
257,258,karpathy,"Was driving a basic 1800 technology car today, forgot that the cruise control does not automagically slow down with a vehicle ahead. Ughh"
258,259,karpathy,Flying to #CVPR17 later tonight! ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets
259,260,karpathy,week late to the party here but experiments on 300M images (300x larger than ImageNet) are awesome   https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html¬†‚Ä¶ 50 K80s 2 months
260,261,karpathy,"""Most metrics are good until you start optimizing for any of them"""
261,262,karpathy,"Pretty sure Facebook app has a bug that doesn't clear old notifications, but they left it in because engagement is up as I keep rechecking"
262,263,karpathy,"But then, I also did 94% on CIFAR-10 and predicted that we won't be able to go above 90% with CNNs, and we all know what happened there."
263,264,karpathy,"i.e. for ImageNet, we went from ~3% to 2.25% in last year. Fun to revisit my 2014 post human vs machine  https://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/¬†‚Ä¶"
264,265,karpathy,en route to Boston for 1 day @ RSS. 35 min from waking up in SF to gate must be my record.
265,266,karpathy,Nice collection of slides & pointers (near the end) on poorly understood / unintuitive properties of Neural Networks https://drive.google.com/file/d/0ByUKRdiCDK7-UXB1R1ZpX082MEk/view¬†‚Ä¶
266,267,karpathy,@udacity @SamuelCox nice! like.
267,268,karpathy,"Driving around PA with a Ludicrous mode Model X, testing a new Autopilot build. I see it will take a while before this gets old."
268,269,karpathy,"@manhuichi oops! I wish I could go to Dublin, sorry about that. All the best with the event!"
269,270,karpathy,@elonmusk @Caenorst 100?? that still leaves 9.7 hours for leisure and sleep.
270,271,karpathy,First week @ Tesla turned into an intense (in a good way!) firehose. I forgot I own a Twitter account.
271,272,karpathy,Berkeley AI Research (BAIR) is launching a blog!  http://bair.berkeley.edu/blog/¬† 1st post from Jacob Andreas @jacobandreas on Neural Module Networks
272,273,karpathy,Measuring the Progress of AI Research  https://www.eff.org/ai/metrics¬† looks quite comprehensive!
273,274,karpathy,@kentf :) good times.
274,275,karpathy,Excited to join Tesla as the Director of AI! https://techcrunch.com/2017/06/20/tesla-hires-deep-learning-expert-andrej-karpathy-to-lead-autopilot-vision/¬†‚Ä¶
275,276,karpathy,"""One Model To Learn Them All"" another step in Google's attempt to turn all of itself into one big neural network  https://arxiv.org/abs/1706.05137¬†"
276,277,karpathy,"@brandondamos Nice! - Cambridge was a great visit when I was around. I met up with @ankurhandos who was postdoc there at time, he might have some pointers"
277,278,karpathy,My regularly scheduled programming has been interrupted by Elon's release of his plan to colonize Mars  http://online.liebertpub.com/doi/pdf/10.1089/space.2017.29009.emu¬†‚Ä¶
278,279,karpathy,Reminder: Deep RL Bootcamp application deadline is today. Take the action:  http://bit.ly/2s5FBPh¬† observe rewards :)
279,280,karpathy,"Oh no, Stanford's Thai Cafe closes down   http://news.stanford.edu/thedish/2017/06/13/the-end-of-an-era-thai-cafe-closes/¬†‚Ä¶ this place was revered as THE model of efficiency. Stuff of myths."
280,281,karpathy,"@Smerity haha yes, not ideal :D e.g. i was going to add @dwf who proposed the idea, but I don't think that's his AS username :) ohwell."
281,282,karpathy,@memimo :)
282,283,karpathy,"e.g. you can click your account (top right) and add me (username ""andrej""). I'll approve and then we're best friends forever."
283,284,karpathy,"so I'm 95% sure I implemented friends feature on arxiv-sanity. Can follow ppl and if accepted see summary of their libs in new ""friends"" tab"
284,285,karpathy,(This is a DeepMind/OpenAI collaboration paper). I like it a lot because it is v promising approach for mitigating perverse instantiations.
285,286,karpathy,"Hand-designed reward functions are the worst. Hence: ""Learning from Human Feedback""  https://deepmind.com/blog/learning-through-human-feedback/¬†‚Ä¶ + https://blog.openai.com/deep-reinforcement-learning-from-human-preferences/¬†‚Ä¶"
286,287,karpathy,@dwf quite easy to implement too I think. Will look into if I can spare some time in the next few days.
287,288,karpathy,@dwf sounds like a good arxiv-sanity feature ;p
288,289,karpathy,"I know I'm very late to the party, but Stratechery is good reading https://stratechery.com/¬†"
289,290,karpathy,maybe it's all generated by a char-rnn. I suspect we will never know.
290,291,karpathy,"The ""Whoa are you serious"" award for an Appendix goes to ""Self-Normalizing Neural Networks""  https://arxiv.org/abs/1706.02515¬† proposes ""selu"" nonlin"
291,292,karpathy,"well, ~1 week -> ~1 hour is ~200x speedup. So... 1 hour -> 0.3 minutes? Surely that can't be right? :) https://twitter.com/jigarkdoshi/status/872882978510090240¬†‚Ä¶"
292,293,karpathy,"Remember ~5 years ago when this took ~1-3 weeks, worked much worse, and required writing complex, custom CUDA kernels?"
293,294,karpathy,"Training ImageNet in 1 hour with 256 GPUs, minibatches of 8192. From  Facebook's FAIR:  https://research.fb.com/publications/ImageNet1kIn1h/¬†‚Ä¶ 1 hour... incredible"
294,295,karpathy,Nice/fun writeup from Ryan Dahl (of node.js fame) on his Google Brain residency  http://tinyclouds.org/residency/¬† accurate assessments allaround
295,296,karpathy,"CS231n poster session, today from 12-3pm at Stanford's Bing Convert Hall! Several hundred projects to go through now... :) pic.twitter.com/51p8T1d9P6"
296,297,karpathy,Excited to see Apple's Core ML. ~2 years ago I had to write manual fragment shaders to do CONV (not fun). Today you can compile Keras models
297,298,karpathy,"@hindupuravinash yeah, trying to fix... thank you!"
298,299,karpathy,"@ZaneSterling thank you, trying to fix... somehow mongo process just decided to shut down."
299,300,karpathy,In this particular stretch you have to shift 4 lanes in 15 seconds because the exit is immediate and on other side. Not part of objective :/
300,301,karpathy,Google Maps prefers a 14 minute route with 10 turns and a stressful/short highway stretch to a 14.5 minute route where you just go forward.
301,302,karpathy,"We are organizing a DeepRL bootcamp, with top notch instructors from Berkeley/DeepMind/OpenAI  http://www.deeprlbootcamp.berkeley.edu/¬† apply by June 16"
302,303,karpathy,"@yoavgo everything we've done so far is ""narrow"" in my definition because we don't have AGI, yet"
303,304,karpathy,New post on placing AlphaGo in context of AI research  https://medium.com/@karpathy/alphago-in-context-c47718cb95a5¬†‚Ä¶ trying to mix in a pinch of low-level depth to popsci/PR
304,305,karpathy,Mary Meeker‚Äôs 2017 internet trends report is making the rounds  http://www.kpcb.com/internet-trends¬† for a good reason - 355 pages of interesting.
305,306,karpathy,Multiple high quality nature videos on the Smithsonian YT channel; e.g. on Cheetah  https://www.youtube.com/watch?v=V8vejjVgIHg¬†‚Ä¶ & more: https://www.youtube.com/user/smithsonianchannel/playlists¬†‚Ä¶
306,307,karpathy,(probably the biggest gotcha that is unique to DL/multi-gpu is to pay attention to the PCIe lanes supported by the CPU/motherboard)
307,308,karpathy,"Quite detailed post on setting up a Deep Learning box from scratch  https://blog.slavv.com/the-1700-great-deep-learning-box-assembly-setup-and-benchmarks-148c5ebe6415¬†‚Ä¶ (I can relate to the CPU install problem, hah)"
308,309,karpathy,@visarga I capped it if I recall correctly. Really? 300? That's a lot of papers for a library. Are you sure you want that many papers in library? :)
309,310,karpathy,@PyTorch @sleepinyourhat i like lineprofiler
310,311,karpathy,"@debuggermassa @sprobertson @soumithchintala yep i was looking at that account this morning, which triggered this tweet :)"
311,312,karpathy,I've been using PyTorch a few months now and I've never felt better. I have more energy. My skin is clearer. My eye sight has improved.
312,313,karpathy,"@nntsn You're right, I incorrectly ""double counted"" their papers. The actual total number is 60 papers, or 6.3% of ICML. Thanks for spotting!"
313,314,karpathy,"Ran some quick numbers on ICML accepted papers  https://medium.com/@karpathy/icml-accepted-papers-institution-stats-bad8d2943f5d¬†‚Ä¶ Google ""wins"" ICML, involved in 10% of papers. ~25% are from industry"
314,315,karpathy,"@vkhosla @samfjacobs that's not something we can do right now. we can set objectives as things that the computer can try/fail at millions of times, like win Go."
315,316,karpathy,@j_jason_bell yes. and we can calculate/show the win margin but not the win probability. it's quite not intuitive that they should be at odds though
316,317,karpathy,also imo an empirical study of this unintuitive consequence of seemingly intuitive objective would make the best kind of AI safety paper.
317,318,karpathy,"certainly not intuitive. a fun glimpse into a future of uncertainty about AI. ""Is it screwing up, or is it actually on a whole new level?"""
318,319,karpathy,"@systemresearch agree. i'd want to see that version too, instead."
319,320,karpathy,it prefers to win by 0.5 with 99.9999999% chance instead of 10.0 with 99.99% chance.
320,321,karpathy,"""Yes AlphaGo only won by 0.5, but it was not at all a close game. It's an artifact of its training objective."" <- me 10 times this morning."
321,322,karpathy,I'm trying to search deep through my Dropbox for my Bitcoin wallet. Pretty sure I mined a few on my laptop back in the old days. Sigh
322,323,karpathy,"Instead of tourism across space I'd love to do pretend time tourism. E.g. ""travel"" to ancient Rome for 2 days, no AD tech allowed, etc."
323,324,karpathy,"@kevin2kelly @44thfloor @NickPinkston sounds highly dubious :) I'd argue the opposite, and especially in the case of AI. I suppose I am biased."
324,325,karpathy,"@kevin2kelly @NickPinkston agree, it read like a lot of hair-splitting that those concerned are largely indifferent to"
325,326,karpathy,"The energy expansions of evolution  https://www.nature.com/articles/s41559-017-0138¬†‚Ä¶ lovely read. geo, sunlight, oxygen, flesh, fire all ""unlocked"" new organisms."
326,327,karpathy,All I want is the grand theory of personality. Seems like ppl quibble about surface corollarys when the real disagreements are fewer/deeper.
327,328,karpathy,"@BrendanEich @marshray hahaha, I like this a lot :D"
328,329,karpathy,"Fun to try come up with N binary questions that ppl answer with 50% yes, and 0 correlation. Info rich. Bit like Myers Briggs but ++"
329,330,karpathy,"@PyTorch @KaiLashArul (the word ""argmax"" was missing from the official docs, search came up with 0 results.)"
330,331,karpathy,"haha. I like good docs. They are under-appreciated by at least a factor of 1,000. https://twitter.com/KaiLashArul/status/865996225476255744¬†‚Ä¶"
331,332,karpathy,"ahh, the arxiv dilemma: put up your A- result now or risk getting scooped by someone with a very similar idea but only B- standards."
332,333,karpathy,"@goodfellow_ian @AlecRad we apply ""directly supervised learning""..."
333,334,karpathy,"@AlecRad @goodfellow_ian Alec has his GPU at home plugged into a naked motherboard, casually on the table. That's how he rolls :)"
334,335,karpathy,Dinner conversation today: @AlecRad revealing his tips and tricks for distinguishing CNN/RNN/RL training by the sound the GPU makes.
335,336,karpathy,based on One-Shot Imitation Learning  https://arxiv.org/abs/1703.07326¬†. My 1st metalearning epiphany was via Matching Networks  https://arxiv.org/abs/1606.04080¬†
336,337,karpathy,what's cool about this is that the policy is parameterized by a demonstration (instead of trained on it); can acquire new skills rapidly.
337,338,karpathy,"At OpenAI we are teaching robots new skills through demonstrations in VR, and it's pretttty cool! Blog+video: https://blog.openai.com/robots-that-learn/¬†‚Ä¶"
338,339,karpathy,"OpenAI released Roboschool: robot simulation envs integrated with OpenAI Gym, based on Bullet instead of MuJoCo. https://blog.openai.com/roboschool/¬†"
339,340,karpathy,"I'm updating my generator 5x as much as my discriminator, and now I feel bad for it because the game is not fair. It's trying its best :("
340,341,karpathy,I found a code base that goes against everything I believe in and stand for as a person. It pains to think that some CPU had to execute that
341,342,karpathy,"NYT article on ransomware  https://www.nytimes.com/2017/05/13/technology/hack-ransomware-scam-cyberattacks.html¬†‚Ä¶ and ""How to Accidentally Stop a Global Cyber Attacks""  https://www.malwaretech.com/2017/05/how-to-accidentally-stop-a-global-cyber-attacks.html¬†‚Ä¶ amazing"
342,343,karpathy,"@Smerity yep that was one of my favorite parts. Some fun/good ideas, but mixed in with lots of crackpot/nonsensical/inconsistent/boring things."
343,344,karpathy,@iandanforth yes but why would anyone want to do that? is the harder piece.
344,345,karpathy,"But wait, why would you want to extract what's in paintings? Can't you just look? Yes, but... other steam engines want to ride your horses."
345,346,karpathy,It's like... a steam engine searching large mathematical expressions over a collection of paintings to extract what's in them? I give up
346,347,karpathy,It's fun to think about how you'd explain e.g. training ResNets on ImageNet to someone from 200 years ago. Even cameras didn't exist.
347,348,karpathy,Inside Volta: The World‚Äôs Most Advanced Data Center GPU  https://devblogs.nvidia.com/parallelforall/inside-volta/¬†‚Ä¶  from the NVIDIA blog
348,349,karpathy,NVIDIA GTC keynote starting any second!! Live video:  http://www.ustream.tv/gpu-technology-conference¬†‚Ä¶  TFLOPs TFLOPs TFLOPs TFLOPs TFLOPs üòç‚åõÔ∏èüéâüóùÔ∏èüìà
349,350,karpathy,"Noticed ppl can be too ""trigger happy"" in throwing RNNs everywhere, when finite contexts (e.g. CNNs) work quite well in many situations."
350,351,karpathy,"MT with CNNs from FB  https://code.facebook.com/posts/1978007565818999/a-novel-approach-to-neural-machine-translation/¬†‚Ä¶ CNNs are nice (shorter causal chain, more parallel), should often be tried in place of RNNs."
351,352,karpathy,"""As We May Program""  https://vimeo.com/215418110¬† fun talk by Peter Norvig. insightful tidbits on challenges of writing modern, complex code."
352,353,karpathy,"Was about 2 weeks. I'm supposed to have highly insightful epiphanies to my work now or something, which I am eagerly awaiting."
353,354,karpathy,"Back from a small whirlwind eurotrip (toulon, rome, florence, venice, pompeii, kosice, bratislava, vienna, dusseldorf). esp liked pompeii"
354,355,karpathy,@brandondamos alex graves has quite a few in his iirc
355,356,karpathy,"@Mvandepanne Neat! On vacation, will look at when I get back!"
356,357,karpathy,"@AdrianoCarmezim No no! Try ""a GAN"". Get it? Haha?"
357,358,karpathy,"""If it doesn't work, try a GAN""."
358,359,karpathy,I only discovered Allbirds üëüa few months ago but they are the best and everyone should have them. https://www.allbirds.com¬†
359,360,karpathy,Sad to spend my favorite day (Earth day) almost entirely in flight. En route to ICLR. üåµüå≤üå≥üå¥üåøüçÄ‚òòÔ∏èüåπüåªüèîüè°
360,361,karpathy,"""Frugal science"": diagnosing malaria on budget  https://www.youtube.com/watch?v=Qf-D1Upn-KU¬†‚Ä¶ Great work, great video."
361,362,karpathy,"And few in ML: The definition of ""unsupervised learning"". The importance of neuroscience to building AI. The review process. Schmidhuber."
362,363,karpathy,"Topics that, if brought up, derail any conversation: Simulation hypothesis. Fermi paradox. AGI. Soylent. Universal Basic Income. Trump."
363,364,karpathy,@adamjsimmons @TorkelD Sony also has a 24-240mm f3.5-6.3; lower quality? & then also + a 55mm f1.8. Odd that sharpness doesn't get quantified on lenses.
364,365,karpathy,"@brianwilt looks great, ty for pointer!"
365,366,karpathy,@adamjsimmons ty! I find the wide lenses look too much like iPhone shots except bigger. Not a huge fan; mostly ok with 24mm+
366,367,karpathy,"@ayman yep thank you, i figured it out now - downloaded & installed a pack of Presets. But it could be more front & center. Lightroom is too pro"
367,368,karpathy,hahahaha :D a fine summary :)
368,369,karpathy,"(playing with my new shiny Sony a7Sii (fullframe, mirrorless), which I quite like! Struggling with what ~2 lenses to get for travel)"
369,370,karpathy,what are all these gazillion sliders in Adobe's Lightroom for processing DSLR images? I really just want a few Instagram filters.
370,371,karpathy,"@github @jekyllrb @pmigdal I didn't turn from it, I just wanted something faster for quick/small posts on a side and didn't want to spam my jekyll blog."
371,372,karpathy,@fferreres yes.
372,373,karpathy,"@AlecRad @EricBattenberg @sedielem Yeah, heard someone say that when you take it out later in training by ""absorbing"" into weights, model trains fine. Can't find the paper ref"
373,374,karpathy,"@sedielem yes, i was trying to reproduce a paper that used N(0,std). As @AlecRad put it, ""friends don't let friends use N(0,std) init"""
374,375,karpathy,"@patrickhop oh, yes- no batchnorms involved in this one for various reasons"
375,376,karpathy,"a 20 layer model. weight init N(0,0.02): stuck completely. try weight init N(0, 0.05): optimizes right away. initialization matters a lot :\"
376,377,karpathy,@gokcen looks great!
377,378,karpathy,"A Computer Scientist‚Äôs View of Life, the Universe and Everything, Schmidhuber 1997  https://arxiv.org/abs/quant-ph/9904050¬†‚Ä¶ I'm ok making this my religion :p"
378,379,karpathy,"""The Website Obesity Crisis""  http://idlewords.com/talks/website_obesity.htm¬†‚Ä¶ fun talk/article spotted on ""Electron is flash for the desktop""  https://news.ycombinator.com/item?id=14087381¬†‚Ä¶"
379,380,karpathy,#funfactsaturdays Humanity collectively experiences the entire age of the Universe every 2 years (as pointed out to me by @catherineols) ha.
380,381,karpathy,"@SebastienBubeck yeah I thought about that title for a while, then eventually decided that some of it is more broad than just DL. but TLDR you're right."
381,382,karpathy,"New quick blog post: ""A Peek at Trends in Machine Learning""  https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106¬†‚Ä¶ a few ""Google Trends"" of ML papers on arxiv"
382,383,karpathy,r/place was an awesome social experiment. A summary post:  http://sudoscript.com/reddit-place/¬† (except the reason for no hate symbols was active banning)
383,384,karpathy,"The TPU is cool, but there is a lot of fine print to ""15-30X faster"". Noticing confusions around. Some discussion: https://www.reddit.com/r/MachineLearning/comments/63mne2/d_quantifying_the_performance_of_the_tpu_our/?st=j16p4z12&sh=5b96f8ae¬†‚Ä¶"
384,385,karpathy,"If a simple autoregressive model discovers sentiment on text, are similar results on videos ""just"" a matter of compute and data?"
385,386,karpathy,"New OpenAI post ""Unsupervised sentiment neuron""  https://blog.openai.com/unsupervised-sentiment-neuron/¬†‚Ä¶ train a big char-rnn on 82M reviews -> SOTA sentiment neuron emerges pic.twitter.com/Y4xVCEcyz5"
386,387,karpathy,"@dennybritz @Smerity ""SanityGAN"""
387,388,karpathy,"@hardmaru oh no, we'll be out by the end of the year!"
388,389,karpathy,"Came to visit first class of @cs231n at Stanford. 2015: 150 students, 2016: 350, this year: 750. #aiinterestsingularity pic.twitter.com/zfPpBOo1vo"
389,390,karpathy,GANs seem to improve on timescales of weeks; getting harder to keep track of. Another impressive paper and I just barely skimmed the other 3
390,391,karpathy,"@fchollet unless running the optimization again takes 1B years of evolution, in which case inspecting a solution might be a decent shortcut."
391,392,karpathy,@Shmuma sometimes the arxiv API suspiciously does not return the newest batch of papers for a few extra hours. Sigh.
392,393,karpathy,"@soswow would be same as is standard for ATARI - e.g. concat last 4 (grayscale) 84x84 frames, feed to a CNN to get actions."
393,394,karpathy,@soswow Would be fun to train with self-play!
394,395,karpathy,"@pterojacktyl hey, thank you for arxiv-sanity support!! üôå"
395,396,karpathy,"I spent 9am to 2am today hunting a single bug, and failed. A great use of 1/365th of one of only several dozen years of my life that remain."
396,397,karpathy,"I was coding when Docker popped up an ""Update?"" dialog. Instead of a newline in my code I accidentally confirmed an Update&Restart. UX fail."
397,398,karpathy,@nikoSuenderhauf ty for supporting arxiv-sanity! üôå
398,399,karpathy,"@kcimc oh you mean at OpenAI? Haha, I'm having a second dinner at a random place in SF, thought that was an odd coincidence or something :)"
399,400,karpathy,@kcimc potentially creepy! ;) where??
400,401,karpathy,"And also 52 startups from YC W17 demo day 1 (from ~week ago, I'm slow)  https://techcrunch.com/2017/03/20/yc-demo-day-winter-2017/¬†‚Ä¶ Like Cowlar, Playment, Boxouse"
401,402,karpathy,"51 startups from YC W17 Demo day 2  https://techcrunch.com/2017/03/21/demo-day-y-combinator/¬†‚Ä¶ A lot of cool stuff! Like Peer5, Zestful, KidPass, Voodoo, Wright"
402,403,karpathy,@iandanforth @jackclarkSF of course not. Linters are very annoying
403,404,karpathy,"New blog post from OpenAI on ""Evolution Strategies as a Scalable Alternative to Reinforcement Learning""  https://blog.openai.com/evolution-strategies/¬†‚Ä¶ w00t!!"
404,405,karpathy,"I already linked to  http://motherfuckingwebsite.com/¬† a few times, if I recall correctly. This is a real problem."
405,406,karpathy,I just have to vent about this. Asana (which we use at OpenAI) takes 5.0 seconds to load a todo list. Of 10 strings. Web has gone Backwards.
406,407,karpathy,Deep Photo Style Transfer  https://arxiv.org/abs/1703.07511¬† wow results. PhotoShop of the future will be amazing. pic.twitter.com/tocKvVs0so
407,408,karpathy,"12 Risks that threaten human civilization  http://www.oxfordmartin.ox.ac.uk/publications/view/1881¬†‚Ä¶ that's a long/depressing pdf (from Feb 2015, Future of Humanity Institute)"
408,409,karpathy,Mask R-CNN  https://arxiv.org/abs/1703.06870¬† results look like ground truth. Also CV ppl write signif. more professional looking papers than ML ppl
409,410,karpathy,"We're expanding our book/textbook library at OpenAI. Curious to hear recommendations on any ""THE book"" on any AI/CS/bio/etc - related topics"
410,411,karpathy,"Excited to join the steering committee of Distill  https://blog.ycombinator.com/distill-an-interactive-visual-journal-for-machine-learning-research/¬†‚Ä¶ 1) exposition is main focus, 2) articles use modern web technology"
411,412,karpathy,@kyield no - i mean unfair to AI researchers who are trying to build similar systems :)
412,413,karpathy,"@notmisha yes, and it was much lower few thousand years ago :) That would be the quite-intelligent subset. Much more unfair if you widen it"
413,414,karpathy,"@ethancaballero It doesn't _really_ make sense to talk about FLOPs in brain, but I saw a few estimates, usually on those orders, 10-1000 PF."
414,415,karpathy,"Nature is evolving ~7 billion ~10 PetaFLOP NI agents in parallel, and has been for ~10M+s of years, in a very realistic simulator. Not fair."
415,416,karpathy,@cholodovskis the pop in ES is resampled so it's fine to apply it in stochastic envs too. Not clear how they compare there. good exp to run
416,417,karpathy,"@cholodovskis agreed that it's better to do e.g. frameskip ~ U[2,4] on each action to make less det. Seems most people not eager to adopt"
417,418,karpathy,"@krasul you can also standardize the rewards z = (x-mu)/std, before the update."
418,419,karpathy,. @DavidVandegrift that's fair :) In our first experiments ES is ~3 orders slower than backprop in SL. The result is mostly relevant to RL.
419,420,karpathy,@Or_Sharir no because i don't want people gamifying it or abusing the system. precise numbers not a good idea here.
420,421,karpathy,You can now understand state of the art AI with before high school math. You forward a neural net and repeat guess&check. works well enough.
421,422,karpathy,"ES is much simpler than RL, and there's no need for backprop, it's highly parallelizable, has fewer hyperparams, needs no value functions..."
422,423,karpathy,RL works so poorly that finite differences are only ~10x worse. & much simpler/more scalable. New paper from OpenAI:  https://arxiv.org/abs/1703.03864¬†
423,424,karpathy,"@Or_Sharir yep, it's the Top tab"
424,425,karpathy,"I've also noticed that my writing style has been drifting over time, likely due to influence of  http://www.paulgraham.com/talk.html¬†, which I agree with."
425,426,karpathy,A quick blog post: ICLR 2017 vs arxiv-sanity https://medium.com/@karpathy/iclr-2017-vs-arxiv-sanity-d1488ac5c131#.egk86sgh8¬†‚Ä¶
426,427,karpathy,"@lukeprog yep, have seen before. btw imo a not usually mentioned effect are incentive structures of those predicting. bias to predict sooner"
427,428,karpathy,"AI experts have agreed for decades that AGI is 20 years away, so I always predict 20 as well. Works nicely.  https://intelligence.org/files/PredictingAI.pdf¬†‚Ä¶ [pdf]"
428,429,karpathy,"""top notch deep learning framework such as MatConvNet or Soumith Chintala"" :D:D. Ok have to stop quoting, there's too much..."
429,430,karpathy,"""Deep generative modelling is probably important (see e.g. Bengio et al. (2013a), ... and (Schmidhuber et al., circa 3114 BC))."" LOL."
430,431,karpathy,"Yes, ""Stopping GAN Violence: Generative Unadversarial Networks""  https://arxiv.org/abs/1703.02528¬† will be the most widely read paper of 2017 :D"
431,432,karpathy,Greg is easily the most productive person I know. And across a wide breadth of tasks. And by a very wide margin. +1 http://blog.samaltman.com/greg¬†
432,433,karpathy,And also direct link to some comments on the Large-Scale Evolution of Image Classifiers paper:  http://arxiv-sanity.com/discuss?id=1703.01041¬†‚Ä¶
433,434,karpathy,"Squeezed in some time over the weekend to implement discussions for arxiv-sanity (Markdown/LaTeX, tags etc.) w00t!:  http://arxiv-sanity.com/discussions¬†"
434,435,karpathy,What it feels like to be an open-source maintainer  https://nolanlawson.com/2017/03/05/what-it-feels-like-to-be-an-open-source-maintainer/¬†‚Ä¶ a sad but true article. And I only experienced ~5% of this
435,436,karpathy,@tadejtadej i watched a house cat randomly viciously attack and kill a colonist
436,437,karpathy,"Oh oh, I'm at a high risk of game addiction, having played a bit of RimWorld last night  https://rimworldgame.com/¬† This can't be happening!"
437,438,karpathy,@TheReibel posted! ;) thank you!
438,439,karpathy,somehow the alarm on my iPhone did not make any sound when it became active this morning. Terrifying. Need to find complete analog solution.
439,440,karpathy,"""Almost every flight today is slower than in the 60s"". Video on how and why the flight times stalled https://www.youtube.com/watch?v=n1QEj09Pe6k¬†‚Ä¶"
440,441,karpathy,üëç we need _much_ more of this. https://twitter.com/sama/status/834101499328237568¬†‚Ä¶
441,442,karpathy,Drama between Uber and Waymo regarding self-driving technology IP. Looks quite bad http://www.theverge.com/2017/2/23/14719906/google-waymo-uber-self-driving-lawsuit-stolen-technology¬†‚Ä¶
442,443,karpathy,"Shake-Shake regularization code  https://github.com/xgastaldi/shake-shake¬†‚Ä¶ claims 2.72% on CIFAR-10. Fun - add more stochastic, even ""break"" backprop."
443,444,karpathy,@Ozan__Caglayan ? you always do early stopping based on validation data
444,445,karpathy,"@humphreysheil i use random search, not grid search (see paper from Bergstra). Never used stuff like Spearmint. As long as it takes :)"
445,446,karpathy,When you run a big hyperparameter search and discover that your default (guessed at) hyperparams work best. Not sure if :) or :(
446,447,karpathy,"@joshbegley very cool! there wouldn't happen to be a dataset of these, I assume? (i work on ML). looks like you can purchase on NYT for alot"
447,448,karpathy,Launch manifest for SpaceX  https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches¬†‚Ä¶ March: 1st stage reuse flight. May: Falcon Heavy demo ü§ìü§ì
448,449,karpathy,"@seanmcarroll Wrote a post on VR recently  https://medium.com/@karpathy/virtual-reality-still-not-quite-there-again-5f51f2b43867#.5ylivpiv3¬†‚Ä¶; see ""The features of doing VR properly"" section for some recommendations"
449,450,karpathy,"""The Egg"" by Andy Weir is still the best short story (per word) I've read so far  http://www.galactanet.com/oneoff/theegg_mod.html¬†‚Ä¶"
450,451,karpathy,"Ted Chiang's ""Understand"" is still the best short story I've read so far, by a margin  https://web.archive.org/web/20140527121332/ http://www.infinityplus.co.uk/stories/under.htm¬†‚Ä¶"
451,452,karpathy,@FerreiraFabioDE possibly negative impact on career :) Stuff took lot of time away from research/papers - most important factor. Meh.
452,453,karpathy,"@OriolVinyalsML ""refuting"" bit strong; ""supplementing"". Could be more careful with ""easily fit random"", ""learn by sheer memorization"", etc"
453,454,karpathy,"you'd be doing everyone a service by essentially ""reverse DDOSing"" the bots."
454,455,karpathy,Hasty-looking but ~good response ( https://openreview.net/pdf?id=rJv6ZgHYg¬†‚Ä¶) refuting some claims of ICLR paper on DNN generalization  https://arxiv.org/abs/1611.03530¬†
455,456,karpathy,"Observing raw web server traffic is fun. Seeing ~frequent requests to (non-existing) /phpmanager/, /sql/phpMyAdmin/, etcetc. probing bots."
456,457,karpathy,"Article on the mirror test which, despite its flaws, is my favorite animal cognition test https://www.theatlantic.com/science/archive/2017/02/what-do-animals-see-in-the-mirror/516348/?single_page=true¬†‚Ä¶"
457,458,karpathy,"Next quarter CS231n will be taught by Justin/Serena/Fei-Fei & available on Stanford's SCPD  http://scpd.stanford.edu/search/publicCourseSearchDetails.do?method=load&courseId=42262144¬†‚Ä¶ (for only $4,800 :))"
458,459,karpathy,@_onionesque running out of laptop battery is like running out of air. It's hibernating till next breath :)
459,460,karpathy,With 2% battery to spare- overnight job started!! thanks to a miraculous midnight intervention by an eng coworker who should be asleep :) https://twitter.com/catherineols/status/832505680418394112¬†‚Ä¶
460,461,karpathy,@debarko :D Shhh Everything is FULLY under control
461,462,karpathy,Great paper from Justin et al. at FAIR on compositional grounded queries diagnostics  https://arxiv.org/abs/1612.06890¬† (from Dec!; I had missed)
462,463,karpathy,I forgot my Macbook charger at work so I'm racing against time to set up this overnight job.Only 17% battery left! This tweet is a bad idea!
463,464,karpathy,"Jack (@jackclarkSF) is doing a great job maintaining a weekly newsletter ""Import AI""  http://us13.campaign-archive1.com/home/?u=67bd06787e84d73db24fb0aa5&id=6c9d98ff2c¬†‚Ä¶"
464,465,karpathy,@brandondamos i'm assuming pytorch copies when it concatenates? you might also have to pull tricks like recomputing parts of fwd pass
465,466,karpathy,"@brandondamos oops just noticed you used growth rate 12 due to GPU limitations, so gap only ~0.2"
466,467,karpathy,"@brandondamos should it get 3.46%, any idea about the remaining gap?"
467,468,karpathy,@sguada PyTorch!! But I'm quite sure TensorFlow will do just fine too :)
468,469,karpathy,"Very nice tutorial from Justin on PyTorch from scratch  https://github.com/jcjohnson/pytorch-examples¬†‚Ä¶ ,stumbled on from ""Practical PyTorch"" https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb¬†‚Ä¶"
469,470,karpathy,Matlab is so 2012. Caffe is so 2013. Theano is so 2014. Torch is so 2015. TensorFlow is so 2016. :D
470,471,karpathy,@georgebastille it worked best of things i tried :)
471,472,karpathy,"@Rob_Bishop you wouldn't by any chance happen to know why fake twitter accounts RTing this paper, right?"
472,473,karpathy,@jackclarkSF @Smerity absolutely - a planned feature for next hacking session. I remember seeing trendingarxiv and then couldn't find again
473,474,karpathy,arxiv-sanity is now migrated & has new feature: sort by hype :p - shows papers that got most tweets over last 5 days  http://arxiv-sanity.com/toptwtr¬†
474,475,karpathy,"Created an image, did a full update, set up hostname, timezone, ssh keys, iptables, cron jobs... Achieved accidental sys admin mastery."
475,476,karpathy,Migrating arxiv-sanity to more permanent home @ Linode. Quite like the service &their docs are great Linux tutorials https://www.linode.com/docs/¬†
476,477,karpathy,@volkuleshov i.e. things that a reviewer might not necessarily catch unless they tried to reproduce the experiments. Hard to protect against
477,478,karpathy,@volkuleshov these were concerns raised by people who tried to reproduce very similar experiments and they found more nuanced takeaways
478,479,karpathy,@volkuleshov there are a few people I've talked to who would have rejected it too though. high variance process
479,480,karpathy,"@vo_d_p unless you really want to automatically detect, localize and track toilets, in which case it's great! ;p"
480,481,karpathy,"@TelemaqueDRF I immediately noticed that too, basically what triggered my mini tweet storm there."
481,482,karpathy,"For image captioning this meant that predicting the single sentence ""A giraffe next to a tree"" worked very well, accurate for lots of imgs."
482,483,karpathy,This was imo a big problem with MSCOCO. Yes it's a lot of data but a third of it were savana animals and another third bathrooms. Strange
483,484,karpathy,YouTube-BB dataset: 10.5M inst of 23 classes  https://research.google.com/youtube-bb/¬† great but what's with the fascination with toilets and giraffes in CV?
484,485,karpathy,"@hyperactve @BrianLester125 yes and this is not super original, heard of ppl doing it 5 years ago, can give 0.5% improvement usually"
485,486,karpathy,"Common usage: ""I thought I was totally starting to overfit at epoch 17, but there is still hope."". ""You need to control your loss addiction"" pic.twitter.com/eyoKQr6ugX"
486,487,karpathy,Loss addiction: self-destructive behavior of obsessively watching & reading into tiny fluctuations in loss functions of running experiments
487,488,karpathy,@EJmz thanks for link! It seems to me that divination should be quite learnable and a serious academic subject.
488,489,karpathy,trying to find more books/articles/work on in-retrospect studies of future predictions (e.g. AC Clarke's Profiles of the Future). fave topic
489,490,karpathy,[batchnorm conv batchnorm relu conv batchnorm] resnet  https://arxiv.org/abs/1610.02915¬† my head hurts. tldr: more batchnorm and less relu.
490,491,karpathy,"+the actual talk on YouTube makes this more visual: ""The Power of Big Data and Psychographics"" https://www.youtube.com/watch?v=n8Dd5aVXLCc¬†‚Ä¶"
491,492,karpathy,"Welcome to the era of big data psychometrics, hyper-targeted advertising, and optimal opinion control  https://motherboard.vice.com/en_us/article/how-our-likes-helped-trump-win¬†‚Ä¶"
492,493,karpathy,"@yosit Hi Yosi haha @ hashtag; flattered :) & always great to hear my work was of help. unf not planning trip that far that soon, sorry & ty"
493,494,karpathy,"Wow, a ""nightmare inducing robot"" indeed, new half-wheeled (?) robot from Boston Dynamics http://www.theverge.com/circuitbreaker/2017/2/1/14468126/boston-dynamics-new-wheeled-robot-handle¬†‚Ä¶"
494,495,karpathy,"@yoavgo I did, MLPs overfit too easily in my case. I used sklearn, they have a sublinear_tf that defaults False, worked few pts better@ True"
495,496,karpathy,@breuderink I only have 1606 users with 5+ libraries. I suspect it's not enough data to do user-based rec. The items have rich features.
496,497,karpathy,@hyperactve not too surprising. SVMs often outperform Softmax classifiers. Can also just use the hinge loss in a neural net without 2 stages
497,498,karpathy,"I didn't try LSTMs. This is all on tfidf vectors, I didn't get fancier than that. It already runs for ~hour+"
498,499,karpathy,@kireetr @edwk simple liblinear through scikit-learn
499,500,karpathy,"@kooswilt arxiv-sanity has 1606 users with 5+ papers in library. I recommend based on all except 1, then check its rank in list (want low)"
500,501,karpathy,"Naive Bayes, recommendation systems, LSI, MLPs, lots of things didn't work. carefully tuned SVM with log-scaled term frequencies worked best"
501,502,karpathy,"Ran a crossval of arxiv-sanity recommendation alg approaches/params. Increased Recall@20 from 0.25 to 0.31, i.e. probly works bit better now"
502,503,karpathy,"@Imran__R it's on my blog, cognitive discontinuity"
503,504,karpathy,Automated astroturfing with chat bots (eg on Reddit/Twitter) is technically very feasible and highly concerning   http://firstmonday.org/ojs/index.php/fm/article/view/6161/5300¬†‚Ä¶
504,505,karpathy,I'm (slowly) writing another short story on AI that I'm super excited about. Except I've been stuck on one passage for a few months. Hard :(
505,506,karpathy,@RaymondRChua @yigitdemirag errr wait maybe direct link is better because videos etc: https://docs.google.com/presentation/d/1lcYrN56V2_SuX1rSmpzOUeMnheF6Jsu33-MsvLW9O_4/edit?usp=sharing¬†‚Ä¶
506,507,karpathy,"@yigitdemirag @RaymondRChua sure, find slides here:  http://alpha.openai.com/ak_rework_2017.pdf¬†‚Ä¶"
507,508,karpathy,@katyanna_q better to email
508,509,karpathy,It took 50 years for the world to install the first million industrial robots. The next million will take only eight https://www.bloomberg.com/gadfly/articles/2017-01-09/the-robot-threat-donald-trump-isn-t-talking-abou¬†‚Ä¶
509,510,karpathy,Aww the Google Self Driving Car project is already part of the Computer _History_ Museum? pic.twitter.com/gBgZug8DSl
510,511,karpathy,@gwern @sherjilozair +1 basically my impression too
511,512,karpathy,"Everything I know about design of ConvNets (resnets, bigger=better, batchnorms etc) is useless in RL. Superbasic 4-layer ConvNets work best."
512,513,karpathy,@TheNickWalsh @AndrewDixonSo wow. It is beautiful & rare that you discover something you know you will use for the rest of your life.
513,514,karpathy,"Dear @AmericanExpress, I got the 100 mails with your AMAZING credit card offer. They aren't just getting lost. Please stop the torture."
514,515,karpathy,@_AntreasAntonio keeps it EXCITING! :)
515,516,karpathy,w00t MIT's Deep Learning for Self-Driving Cars class uses ConvNetJS. DeepTraffic:  http://selfdrivingcars.mit.edu/deeptraffic/¬† &DeepTesla  http://selfdrivingcars.mit.edu/deeptesla/¬†
516,517,karpathy,"Imperative, dynamic graph construction is going strong recently, also with recent & v nice looking minpy  https://github.com/dmlc/minpy¬†, DyNet, etc"
517,518,karpathy,"Excited to see PyTorch (a new Deep Learning library) released! Tried it for few days, it is awesome: imperative!, fast, clean and simple. https://twitter.com/PyTorch/status/821782189780172810¬†‚Ä¶"
518,519,karpathy,"""Personally, I do not trust paper results at all. I tend to read papers for inspiration"" A correct rant. http://blog.dennybritz.com/2017/01/17/engineering-is-the-bottleneck-in-deep-learning-research/¬†‚Ä¶"
519,520,karpathy,"Wrote up some thoughts on VR (long interest of mine) in a blog post: ""Virtual Reality: still not quite there, again"" https://medium.com/@karpathy/virtual-reality-still-not-quite-there-again-5f51f2b43867#.tswz9cbg4¬†‚Ä¶"
520,521,karpathy,"@deanpomerleau I don't buy the simulation stuff, too human centric. can accept a QM cellular automaton with us as just some funny pattern"
521,522,karpathy,"@deanpomerleau sure, it's a special case of the Fermi paradox."
522,523,karpathy,@sameersoi it's more of a special case of the Fermi paradox
523,524,karpathy,I don't understand why Earth over last few B years was not an easy target for an alien superintelligence when galaxy is only ~100k LY across
524,525,karpathy,"@soumithchintala For this reason I also wouldn't endorse as far as working from home, because you do miss on many in-person comms."
525,526,karpathy,@soumithchintala I still get lunch/dinner/go to various meetings daily. I have a suspicion that this is enough & rest is mostly fun fluff
526,527,karpathy,I sequestered myself in a conference room last week (was ill) instead of open seating & RescueTime shows 1.8x more productivity. Interesting
527,528,karpathy,Greg's post on past/present/future of OpenAI  https://blog.gregbrockman.com/define-cto-openai¬†‚Ä¶ including fun stories of OpenAI early days
528,529,karpathy,@DARPA @juddydotg yes.
529,530,karpathy,@ashiq @adamajm a quick/ugly/temporary hack brought it back. i'll have to properly sit down at some point and fix everything.
530,531,karpathy,@adamajm uh oh. with growing library of papers and my fairly lazy code the serving process started running out of memory over time. Panic!!!
531,532,karpathy,"Not clear why TF still really likes `reduce_` syntax bloat, or `keep_dims` vs numpy's `keepdims`, etc."
532,533,karpathy,"TensorFlow 1.0.0-alpha  https://github.com/tensorflow/tensorflow/releases¬†‚Ä¶ many numpy API compatibility changes are very welcome, seems could still go even further"
533,534,karpathy,@soumithchintala seems like quite a difficult and tricky technical problem that companies are not thinking through nearly enough.
534,535,karpathy,"TV anchor says ""Alexa order me a dollhouse"" on live TV, Alexas in people's homes activate and go on shopping spree http://www.theregister.co.uk/2017/01/07/tv_anchor_says_alexa_buy_me_a_dollhouse_and_she_does/¬†‚Ä¶"
535,536,karpathy,"@jrheard @kenstruys replied, hope it helps!"
536,537,karpathy,"Local news from Mission SF  http://missionlocal.org/2016/12/man-stabbed-in-face-woman-threatened-with-crack-pipe-in-robberies/¬†‚Ä¶ each time: ""[something terrible] @ [a place I walk by all the time]. no arrests made."""
537,538,karpathy,"@tryolabs looks great! i've never actually done the batch norm gradient derivation, it looks long and painful ;)"
538,539,karpathy,Fun fact 27/120: There are nuclear submarines out there carrying 40 nuclear warheads controlled by a computer running Windows XP.
539,540,karpathy,People aren't anywhere nearly enough scared shitless about the world's aging nuclear arsenal and its problems http://www.newyorker.com/news/news-desk/world-war-three-by-mistake¬†‚Ä¶
540,541,karpathy,@onkarjoshi @bjorn I have no choice they insist. They have applications they are familiar with and unwilling to hear about a switch
541,542,karpathy,"Doing an annual clean up of my parents' windows laptop. A Wild West of adware/garbage accumulated, each very unwilling to be uninstalled"
542,543,karpathy,"V amusing read on cat-proofing feeder ""The trick is to be smarter than the animal with a brain the size of a walnut""  http://quinndunki.com/blondihacks/?p=3023¬†‚Ä¶"
543,544,karpathy,A short/quick blog post: ‚ÄúYes you should understand backprop‚Äù https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.i6uw5v303¬†‚Ä¶
544,545,karpathy,@yoavgo @naivebayesian Also have a higher level recent talk that could have some good fit https://docs.google.com/presentation/d/1xxtoP4G4WogHv4U_vB2ILFcqbBNG-l0SzplZkuipcE4/edit?usp=sharing¬†‚Ä¶
545,546,karpathy,"w00t, up to 10x faster fp16 gemm kernels than cuBLAS, from @scottgray76 https://twitter.com/soumithchintala/status/810483084286160896¬†‚Ä¶"
546,547,karpathy,"@dvigneshwer sorry, i mean it's for strong (web) engineers first. Experience with AI/ML certainly a plus."
547,548,karpathy,"@dvigneshwer we are creating web environments benchmarks to get AIs to understand & navigate buttons/forms/etc., complete tasks."
548,549,karpathy,+We are looking to hire engineers to help us create more web environments for AI agents. Ping me at karpathy@openai.com if interested!
549,550,karpathy,More on Mini World of Bits project (agents learn to use the web) at OpenAI and how to use it with Universe:  http://alpha.openai.com/miniwob/index.html¬†‚Ä¶ pic.twitter.com/2HKG4H1t6Y
550,551,karpathy,@yazinsai Planning to give it a try over the winter break! :)
551,552,karpathy,"Finally finished Rhodes' tome ""The Making of the Atomic Bomb"". Great but a bit loooong. Review/summary/comments: https://www.goodreads.com/review/show/1385479805¬†‚Ä¶"
552,553,karpathy,"John Schulman's slides from today's ""nuts and bolts of RL"", great practical advice for getting RL to work  http://rll.berkeley.edu/deeprlcourse/docs/nuts-and-bolts.pdf¬†‚Ä¶"
553,554,karpathy,There are surprisingly many surprisingly aggressive security guards at this years #NIPS2016
554,555,karpathy,Best party of #nips2016 award goes to #rocketai ( http://rocketai.org/¬†). Definitely a company to watch closely.
555,556,karpathy,"@knormand29 was down, brought it back up. we had a planned outage."
556,557,karpathy,@yigitdemirag RNN!!
557,558,karpathy,"@drewvolpe ""readers also liked"" - good, easy to add idea. hmmm"
558,559,karpathy,"Marc Raibert of Boston Dynamics gave a very nice talk @ NIPS on robots. +fun pointers, e.g. swearing robot spoof: https://www.youtube.com/watch?v=zkv-_LqTeQA¬†‚Ä¶"
559,560,karpathy,"Also, I'm really hoping to start seeing pretrained agents on Universe, similar to the pervasiveness of pretrained ConvNets on ImageNet."
560,561,karpathy,Also very excited the ease of collecting human demonstrations on any env in Universe. RL alone doesn't make sense when SL data is near free.
561,562,karpathy,"With near infinite supply of envs that all ""look the same"" in Universe, I'm really hoping we can finally see convincing results on transfer."
562,563,karpathy,"In case you missed it, OpenAI released Universe:  https://openai.com/blog/universe/¬† AI agents remote desktop into Docker containers. Really awesome"
563,564,karpathy,We're going to NIPS to talk about ICLR papers
564,565,karpathy,‚ÄúDeep Learning the Stock Market‚Äù by @thetalperry  https://medium.com/@TalPerry/deep-learning-the-stock-market-df853d139e02#.7sw9pdz66¬†‚Ä¶. I often enjoy posts from ppl newish to DL - diff ways of thinking
565,566,karpathy,"Google Earth Timelapse: see 1984 -> 2016  http://waitbutwhy.com/2016/12/sheer-delight-google-earth-timelapse.html¬†‚Ä¶ extremely depressing. cancer cities, massive deforestation, ice melting"
566,567,karpathy,Most of us at OpenAI watching this now. https://twitter.com/j_gauthier/status/804045779035820033¬†‚Ä¶
567,568,karpathy,@bleyddyn LOL. absolutely.
568,569,karpathy,"@michael_nielsen our bodies are too damn efficient. A really good feature until recently, a cruel bug since."
569,570,karpathy,I ran for 20 minutes yesterday and burned 260 cals. That's 11 square blocks of my favorite chocolate in our microkitchen. cruel world :(
570,571,karpathy,@AndrewYNg The Making of the Atomic Bomb by Rhodes
571,572,karpathy,This year's NIPS (happening in a week!!!1) will be:
572,573,karpathy,@karpathy (i just wanted to make sure that people understand that this is a joke...)
573,574,karpathy,"3e-4 is the best learning rate for Adam, hands down."
574,575,karpathy,@TimHaines Cafe Venetia and Old Union are both highly suspicious. I visited each 5 times max last year but I have 16/18 charges from them
575,576,karpathy,I also discovered that a Palo Alto cafe charged me 18 times except I went there ~twice ever. Multiple for same amount ($7.94). What.
576,577,karpathy,Downloaded my bank data as csv & hacking out plots. They don't make it easy. They export addresses (which have commas) in CSV files. Great.
577,578,karpathy,Following World Chess Championship a bit. All 7 games so far were draw ( https://fivethirtyeight.com/features/kids-love-the-world-chess-championship-even-the-draws/?ex_cid=story-twitter¬†‚Ä¶). 8th live stream: https://www.twitch.tv/chessnetwork¬†
578,579,karpathy,Finished Black Mirror season 3. Favorite eps: 6 > 1 > 4 > 5 > 2 > 3. Black Mirror is sadly too relevant today.
579,580,karpathy,@sguada oh. Yeah. Good point :)
580,581,karpathy,@hardmaru :) imo there can be quite decent visual improvements for every 0.01 when you're that far down.
581,582,karpathy,"Also worth trying the PixelCNN as the decoder in all the things instead of ""vanilla"" deconv stack; it's powerful. Except slower to sample :("
582,583,karpathy,"Btw ~week ago we released PixelCNN++, a nice/efficient multi-GPU TensorFlow code, SOTA generative model on CIFAR-10 https://github.com/openai/pixel-cnn¬†‚Ä¶"
583,584,karpathy,@LesGuessing I went through the same experience exactly. Was ready to be superman and instead was a weird gozilla with restricted vision
584,585,karpathy,"@VahidK I did, I liked it. Except it was 5 minutes and the team seems to have disappeared since."
585,586,karpathy,@jackclarkSF not too much but I think they're still missing some critical features. It's like what Paint is to Photoshop. Oh & multiplayer!!
586,587,karpathy,"@karpathy so far my viscerally interesting favorites with potential are Tilt Brush, AudioShield/HoloPoint, and AltspaceVR"
587,588,karpathy,"Tried out Google Earth VR in Vive. Had high hopes but it's a half-baked ""kinda cool"" tech demo I won't go back to. Like most other things VR"
588,589,karpathy,@karpathy a core yelp functionality appears to be `if comment.substring(query): return comment`.
589,590,karpathy,"when you search ""best ribs"" on Yelp the first result is a place with someone's review that says ""Not the best ribs I've had..."". great."
590,591,karpathy,"@gwern yeah but I still can't quite internalize that it should be that ""dumb"" and work fine"
591,592,karpathy,monster Multilingual MT system  https://arxiv.org/abs/1611.04558¬† 3 weeks on 100 GPUs. Just append target language token to source sentence  ¬Ø\_(„ÉÑ)_/¬Ø
592,593,karpathy,(my very top recommendations have been rainfall videos for the last month because I tried it out once for coding)
593,594,karpathy,"If you play ambiance music on YouTube once be prepared to be recommended more forever. It thinks you *love* it after ""watching"" it for hours"
594,595,karpathy,"Watched Arrival last night and didn't like it, probably because I read the short story (which is MUCH better/consistent/believable) first."
595,596,karpathy,"Visiting Stanford briefly today. In case you were wondering where arxiv sanity lives, my old box picture :D should move to cloud sometime... pic.twitter.com/XeANIt8pH7"
596,597,karpathy,@egrefen this is my pet peeve chart. The y-axis starts at 58M. Arbitrarily misleading visualization.
597,598,karpathy,"Looking forward to guest lecture at Stanford's ""Minds and Machines"" class on Thursday  https://web.stanford.edu/class/symsys1/¬† the course slides are nice!"
598,599,karpathy,"A wonderful passage on Quora ( https://www.quora.com/Do-book-lovers-look-down-on-non-readers/answers/886844¬†‚Ä¶) about reading/writing books, become a part of an meme medium that spans time. pic.twitter.com/laTvYyiypz"
599,600,karpathy,"@michael_nielsen @_onionesque Zomg I had lost the link to that post, so wonderful to re-discover it!"
